<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Intro</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html" rel="" target="">
 <span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html" rel="" target="">
 <span class="menu-text">About Me</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../cooking.html" rel="" target="">
 <span class="menu-text">Cooking</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools ms-auto">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-page-left">
      <h1 class="title">Intro</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#whats-dic" id="toc-whats-dic" class="nav-link active" data-scroll-target="#whats-dic">What’s DIC?</a></li>
  <li><a href="#importance-of-predicting-dic" id="toc-importance-of-predicting-dic" class="nav-link" data-scroll-target="#importance-of-predicting-dic">Importance of Predicting DIC</a>
  <ul class="collapse">
  <li><a href="#using-ml" id="toc-using-ml" class="nav-link" data-scroll-target="#using-ml">Using ML</a></li>
  <li><a href="#equity-consequences" id="toc-equity-consequences" class="nav-link" data-scroll-target="#equity-consequences">Equity Consequences</a></li>
  </ul></li>
  <li><a href="#tools-and-techniques" id="toc-tools-and-techniques" class="nav-link" data-scroll-target="#tools-and-techniques">Tools and Techniques</a></li>
  <li><a href="#data-exploration-and-preprocessing" id="toc-data-exploration-and-preprocessing" class="nav-link" data-scroll-target="#data-exploration-and-preprocessing">Data Exploration and Preprocessing</a></li>
  <li><a href="#model-selection-and-training" id="toc-model-selection-and-training" class="nav-link" data-scroll-target="#model-selection-and-training">Model Selection and Training</a></li>
  <li><a href="#model-evaluation-and-interpretation" id="toc-model-evaluation-and-interpretation" class="nav-link" data-scroll-target="#model-evaluation-and-interpretation">Model Evaluation and Interpretation</a></li>
  <li><a href="#implications-and-future-work" id="toc-implications-and-future-work" class="nav-link" data-scroll-target="#implications-and-future-work">Implications and Future Work</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  <li><a href="#acknowledgments" id="toc-acknowledgments" class="nav-link" data-scroll-target="#acknowledgments">Acknowledgments</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block column-page-left" id="quarto-document-content">




<p>A. CalCOFI dataset 1. Importance in oceanographic research 2. Long-term data collection (70+ years) 3. Physical, chemical, and biological properties</p>
<section id="whats-dic" class="level2">
<h2 class="anchored" data-anchor-id="whats-dic">What’s DIC?</h2>
<p>Dissolved inorganic carbon (DIC) is an crucial component of the ocean’s carbon cycle and has significant implications for the health of marine life and climate change as well. Image this: instead of fluid, the ocean is a massive sponge that soaks up carbon dioxide from the atmosphere. Over time, the carbon dioxide dissolves into the water and transforms into different types of dissolved inorganic carbon like carbonic acid and bicarbonate (I won’t cover the chemistry of this transition, but you can learn more about that at <span class="citation" data-cites="ScienceDirect">[@ScienceDirect]</span>). These types of DIC are kept steady by the pH levels of the ocean (roughly 8.1). Now imagine the sponge, already full, trying to squeeze in more carbon dioxide. This is where things are at at this moment in time: humans are stuffing more carbon dioxide into the atmosphere by burning fossil fuels and cutting down forests, whcih is causing the oceans to absord more carbon dioxide than they are equipped to handle. Increasing the amounts of carbon dioxide in the ocean leads to a malicious process called ocean acidification. The higher carbon dioxide absorption causes a shiftin the delicate balance of DIC in the ocean, causing a decrease in the ocean’s pH level. This is bad news bears for almost anything and everything living in the ocean.</p>
<p>Ocean acidification can have serious consequences on marine organisms that rely on calcification to build their skeletons and shells. Organisms include coral, plankton, crabs, lobsters, and more. And think about this: coral reefs are home to an abundance of life. Often referred to as the rainforests of the sea, coral reefs cover less than one percent of the ocean floor, but support roughly 25 percent of all known marine species. Pretty incredible, and for all of these animals to be put in danger as well makes the impact of ocean acidification nearly incomprehensible. Here’s some science for you: as the ocean gets more acidic, there is a lower supply of carbonate ions which in turns makes it challening for these organisms that rely on calcification to actually build their structures. This reminds me of a situation where the half of the wood on Earth gets infested with something and is unusable, causing the construction industry to go down, then all goods-producing industries, then subsequently every other industry in the global economy to just crash and burn. Coral reefs technically have it even worse than the shellfish since they face the impact of reduced calcification rates AND higher rates of dissolution of their calcium carbonate structures (or backbone). Ocean acidification has extreme consequences, and it is our obligation to limit it as best we can.</p>
<p>To make maters worse, rising ocean temperatures and deviations in typical oceanographic patterns can impact the spread and cycle of DIC across the ocean. Warmer waters aren’t able to absorb as much carbon dioxide, so as the ocean rises it is likely going to be the case that less carbon is actually drawn from the atmosphere and absorbed by the ocean. Double whammie!</p>
<p>Here is what can be done: reduce our carbon emissions and restore coastal ecosystems, and we could be in luck!</p>
</section>
<section id="importance-of-predicting-dic" class="level2">
<h2 class="anchored" data-anchor-id="importance-of-predicting-dic">Importance of Predicting DIC</h2>
<section id="using-ml" class="level3">
<h3 class="anchored" data-anchor-id="using-ml">Using ML</h3>
<p>If we want to tackle the challenges posed by ocean acidification and climate change, we need to be able to predict DIC levels accurately. Here where machine learning comes in to play.</p>
<p>By harnessing the power of data and advanced algorithms, we can develop models that help us assess the extent of ocean acidification across different locations and time scales. This is critical for understanding the potential impacts on marine ecosystems and identifying the areas that are most vulnerable. Predicting DIC levels also enables us to establish specific, tailored, and powerful mitigation strategies. By anticipating future changes in DIC and their consequences, we can make informed, (hopefully) accurate decisions about how to allocate resources, prioritize conservation efforts, and adapt our management approaches. That sounds wonderful!</p>
<p>In this analysis, my goal was to build a predictive model for DIC using a machine learning approach. I found that XGBoost, a powerful algorithm known for its ability to handle complex relationships and deliver accurate predictions, was the best model based on the data set we were given. I tried a few Random Forest methods, but did not get quite the same results as from XGBoost. By training the model on a dataset of various oceanographic parameters, such as temperature, salinity, and nutrient concentrations, the goal was to capture and understand the underlying patterns and relationships that influence DIC levels. I also dove deep into the data, exploring the distributions, correlations, and potential multicollinearity among the variables. This let me gain (and now you, the reader) a more holistic understanding of the factors at play.</p>
</section>
<section id="equity-consequences" class="level3">
<h3 class="anchored" data-anchor-id="equity-consequences">Equity Consequences</h3>
<p>The impacts of elevated DIC levels on marine ecosystems extend far beyond the realm of environmental conservation. They have profound socio-economic implications that ring through coastal communities and beyond. Many of these communities rely heavily on the health and productivity of marine environments for their livelihoods, and the degradation of these ecosystems can have severe consequences.</p>
<p>Consider the coral reefs again, which are particularly vulnerable to ocean acidification. These underwater hotspots are not only beautiful but also serve as the foundation for thriving ecosystems that support an astonishing diversity of life. Coral reefs attract tourists from around the world, generating significant revenue for local economies through activities such as snorkeling, diving, and beach tourism. However, as DIC levels rise and the ocean becomes more acidic, the delicate balance that sustains these reefs is disrupted. The deterioration of coral reefs can lead to a landslide of ecological effects, culminating in the loss of biodiversity and the decline of the tourism industry that relies on their allure.</p>
<p>Moreover, the socio-economic consequences of elevated DIC levels extend to the realm of fisheries. Lots of coastal communities rely on fishing as a primary source of both sustenance and income. As ocean acidification alters the chemistry of precious waters, it can have detrimental effects on the growth, survival, and reproduction of many marine species. The destruction of fish populations and altered species distributions can have severe implications for the livelihoods of fishermen and the communities they support. The loss of income and food security can ripple through these societies, exacerbating poverty and social instability. For many coastal communities, the ocean is not merely a resource to be exploited but an integral part of their cultural heritage and identity. The degradation of marine environments can erode the very fabric of these societies, undermining traditional practices, knowledge systems, and social structures that have evolved in harmony with the sea. The loss of cultural heritage and the severing of deep-rooted connections to the ocean can have profound psychological and emotional consequences for these communities.</p>
</section>
</section>
<section id="tools-and-techniques" class="level2">
<h2 class="anchored" data-anchor-id="tools-and-techniques">Tools and Techniques</h2>
<p>I worked in Python and used its ecosystems of data science libraries, such as pandas, matplotlib, and scikit-learn. Utilizing techniques like cross-validation and hyperparameter tuning, I storve to build a sturyd and generalizable pipeline that serves as a small example of how data science can help curb the effects of the climate crisis.</p>
<div class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import libraries</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np </span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, GradientBoostingRegressor</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, RandomizedSearchCV, cross_val_score, GridSearchCV</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, mean_absolute_error, r2_score</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> xgboost <span class="im">import</span> XGBRegressor</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_selection <span class="im">import</span> RFE</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.linear_model <span class="im">import</span> LinearRegression</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, RegressorMixin</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.svm <span class="im">import</span> SVR</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> StandardScaler</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> make_pipeline</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-exploration-and-preprocessing" class="level2">
<h2 class="anchored" data-anchor-id="data-exploration-and-preprocessing">Data Exploration and Preprocessing</h2>
<ul>
<li>Highlight any interesting insights or patterns you discovered during exploratory analysis</li>
</ul>
<p>First, the data is read in and quickly cleaned up.</p>
<div class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in data</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">"data/training.csv"</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>test_data <span class="op">=</span> pd.read_csv(<span class="st">'data/test.csv'</span>)</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove the NA values</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.drop(<span class="st">'Unnamed: 12'</span>, axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename columns to match test data</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> data.rename(columns<span class="op">=</span>{<span class="st">'TA1.x'</span>: <span class="st">'TA1'</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>data.columns</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>Index(['id', 'Lat_Dec', 'Lon_Dec', 'NO2uM', 'NO3uM', 'NH3uM', 'R_TEMP',
       'R_Depth', 'R_Sal', 'R_DYNHT', 'R_Nuts', 'R_Oxy_micromol.Kg', 'PO4uM',
       'SiO3uM', 'TA1', 'Salinity1', 'Temperature_degC', 'DIC'],
      dtype='object')</code></pre>
</div>
</div>
<p>The dataset encompasses a wide array of oceanographic variables that can potentially influence dissolved inorganic carbon (DIC) levels in the ocean. Key features include latitude and longitude (Lat_Dec, Lon_Dec), which provide spatial context and can capture regional variations in DIC. Nutrient concentrations such as nitrite (NO2uM), nitrate (NO3uM), ammonia (NH3uM), phosphate (PO4uM), and silicate (SiO3uM) are essential for marine primary production and can affect the biological pump that influences DIC levels. Physical parameters like temperature (R_TEMP, Temperature_degC), depth (R_Depth), salinity (R_Sal, Salinity1), and dynamic height (R_DYNHT) play crucial roles in determining the solubility and distribution of DIC in the water column. Dissolved oxygen (R_Oxy_micromol.Kg) and total alkalinity (TA1) are closely linked to the carbonate system and can provide insights into the carbonate chemistry that regulates DIC concentrations.</p>
<div class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Distribution of DIC in data</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">6</span>))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>plt.hist(data[<span class="st">'DIC'</span>], bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'DIC'</span>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Frequency'</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Distribution of DIC'</span>)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="analysis_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>The distribution of DIC is somewhat bimodal, with beaks around 2000 and 2300.</p>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Correlation heatmap</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>sns.heatmap(data.corr(), annot<span class="op">=</span><span class="va">True</span>, cmap<span class="op">=</span><span class="st">'coolwarm'</span>, square<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Correlation Heatmap'</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="analysis_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Even a quick glance reveals that there are some strong levels working in the data across the different features. While some are obviosuly 1 (like temperature in farenheit and celcius), closely examining the heatmap gives us lots of insights into how the features are related to each other, and look into the issue over multicollinearity.</p>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Looking for outliers</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>data.boxplot(column<span class="op">=</span>[<span class="st">'Lat_Dec'</span>, <span class="st">'Lon_Dec'</span>, <span class="st">'NO2uM'</span>, <span class="st">'NO3uM'</span>, <span class="st">'NH3uM'</span>, <span class="st">'R_TEMP'</span>, <span class="st">'R_Depth'</span>, <span class="st">'R_Sal'</span>, <span class="st">'R_DYNHT'</span>, <span class="st">'R_Nuts'</span>, <span class="st">'R_Oxy_micromol.Kg'</span>, <span class="st">'PO4uM'</span>, <span class="st">'SiO3uM'</span>, <span class="st">'TA1'</span>, <span class="st">'Salinity1'</span>, <span class="st">'Temperature_degC'</span>, <span class="st">'DIC'</span>])</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Boxplots of Numerical Features'</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="analysis_files/figure-html/cell-7-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>Might have to do some normalizing, I’m not totally sure yet.</p>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>corr_matrix <span class="op">=</span> data.corr()</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Correlation Matrix:"</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(corr_matrix)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation Matrix:
                         id   Lat_Dec   Lon_Dec     NO2uM     NO3uM     NH3uM  \
id                 1.000000 -0.038276  0.032081  0.010521 -0.010648 -0.008376   
Lat_Dec           -0.038276  1.000000  0.143350  0.092121  0.047306  0.025656   
Lon_Dec            0.032081  0.143350  1.000000  0.026807  0.018539  0.063730   
NO2uM              0.010521  0.092121  0.026807  1.000000 -0.127036  0.115571   
NO3uM             -0.010648  0.047306  0.018539 -0.127036  1.000000 -0.271022   
NH3uM             -0.008376  0.025656  0.063730  0.115571 -0.271022  1.000000   
R_TEMP             0.006920 -0.021435  0.045179  0.020522 -0.933583  0.228610   
R_Depth            0.030571 -0.143631 -0.111881 -0.029772  0.508515 -0.145500   
R_Sal              0.006151 -0.069319 -0.026433  0.032799 -0.957965  0.228303   
R_DYNHT            0.015389 -0.167146 -0.121625 -0.045207  0.762652 -0.228297   
R_Nuts            -0.008376  0.025656  0.063730  0.115571 -0.271022  1.000000   
R_Oxy_micromol.Kg  0.012270 -0.098267 -0.085730  0.052974 -0.965962  0.280080   
PO4uM             -0.008988  0.091319  0.048614 -0.008006  0.976118 -0.256997   
SiO3uM             0.013965 -0.016170 -0.053141  0.010939  0.857180 -0.242184   
TA1                0.018413  0.018881  0.030687 -0.005523  0.792031 -0.190671   
Salinity1          0.006179  0.103488  0.138710 -0.076072  0.918598 -0.226156   
Temperature_degC   0.007114 -0.022524  0.044673  0.020409 -0.933754  0.228463   
DIC               -0.008105  0.077621  0.044557 -0.026785  0.979850 -0.252974   

                     R_TEMP   R_Depth     R_Sal   R_DYNHT    R_Nuts  \
id                 0.006920  0.030571  0.006151  0.015389 -0.008376   
Lat_Dec           -0.021435 -0.143631 -0.069319 -0.167146  0.025656   
Lon_Dec            0.045179 -0.111881 -0.026433 -0.121625  0.063730   
NO2uM              0.020522 -0.029772  0.032799 -0.045207  0.115571   
NO3uM             -0.933583  0.508515 -0.957965  0.762652 -0.271022   
NH3uM              0.228610 -0.145500  0.228303 -0.228297  1.000000   
R_TEMP             1.000000 -0.583892  0.986747 -0.798440  0.228610   
R_Depth           -0.583892  1.000000 -0.543556  0.904710 -0.145500   
R_Sal              0.986747 -0.543556  1.000000 -0.771583  0.228303   
R_DYNHT           -0.798440  0.904710 -0.771583  1.000000 -0.228297   
R_Nuts             0.228610 -0.145500  0.228303 -0.228297  1.000000   
R_Oxy_micromol.Kg  0.869693 -0.432215  0.913799 -0.709405  0.280080   
PO4uM             -0.928439  0.499634 -0.956169  0.762081 -0.256997   
SiO3uM            -0.861262  0.806016 -0.856864  0.936014 -0.242184   
TA1               -0.757048  0.786738 -0.783237  0.890010 -0.190671   
Salinity1         -0.823260  0.567344 -0.890545  0.764865 -0.226156   
Temperature_degC   0.999983 -0.579262  0.986931 -0.795282  0.228463   
DIC               -0.936952  0.555750 -0.963751  0.797196 -0.252974   

                   R_Oxy_micromol.Kg     PO4uM    SiO3uM       TA1  Salinity1  \
id                          0.012270 -0.008988  0.013965  0.018413   0.006179   
Lat_Dec                    -0.098267  0.091319 -0.016170  0.018881   0.103488   
Lon_Dec                    -0.085730  0.048614 -0.053141  0.030687   0.138710   
NO2uM                       0.052974 -0.008006  0.010939 -0.005523  -0.076072   
NO3uM                      -0.965962  0.976118  0.857180  0.792031   0.918598   
NH3uM                       0.280080 -0.256997 -0.242184 -0.190671  -0.226156   
R_TEMP                      0.869693 -0.928439 -0.861262 -0.757048  -0.823260   
R_Depth                    -0.432215  0.499634  0.806016  0.786738   0.567344   
R_Sal                       0.913799 -0.956169 -0.856864 -0.783237  -0.890545   
R_DYNHT                    -0.709405  0.762081  0.936014  0.890010   0.764865   
R_Nuts                      0.280080 -0.256997 -0.242184 -0.190671  -0.226156   
R_Oxy_micromol.Kg           1.000000 -0.984506 -0.845775 -0.801070  -0.929567   
PO4uM                      -0.984506  1.000000  0.887765  0.824866   0.925998   
SiO3uM                     -0.845775  0.887765  1.000000  0.957445   0.870885   
TA1                        -0.801070  0.824866  0.957445  1.000000   0.897201   
Salinity1                  -0.929567  0.925998  0.870885  0.897201   1.000000   
Temperature_degC            0.870070 -0.928617 -0.859068 -0.754551  -0.822527   
DIC                        -0.978868  0.994955  0.908763  0.852646   0.940914   

                   Temperature_degC       DIC  
id                         0.007114 -0.008105  
Lat_Dec                   -0.022524  0.077621  
Lon_Dec                    0.044673  0.044557  
NO2uM                      0.020409 -0.026785  
NO3uM                     -0.933754  0.979850  
NH3uM                      0.228463 -0.252974  
R_TEMP                     0.999983 -0.936952  
R_Depth                   -0.579262  0.555750  
R_Sal                      0.986931 -0.963751  
R_DYNHT                   -0.795282  0.797196  
R_Nuts                     0.228463 -0.252974  
R_Oxy_micromol.Kg          0.870070 -0.978868  
PO4uM                     -0.928617  0.994955  
SiO3uM                    -0.859068  0.908763  
TA1                       -0.754551  0.852646  
Salinity1                 -0.822527  0.940914  
Temperature_degC           1.000000 -0.936781  
DIC                       -0.936781  1.000000  </code></pre>
</div>
</div>
<div class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.decomposition <span class="im">import</span> PCA</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract the feature columns</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>X_features <span class="op">=</span> data.drop([<span class="st">'DIC'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform PCA</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>pca <span class="op">=</span> PCA()</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>pca.fit(X_features)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Explained variance ratio</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>explained_variance_ratio <span class="op">=</span> pca.explained_variance_ratio_</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Explained Variance Ratio:"</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, ratio <span class="kw">in</span> <span class="bu">enumerate</span>(explained_variance_ratio):</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Principal Component </span><span class="sc">{</span>i<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>ratio<span class="sc">:.3f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Explained Variance Ratio:
Principal Component 1: 0.560
Principal Component 2: 0.400
Principal Component 3: 0.038
Principal Component 4: 0.002
Principal Component 5: 0.000
Principal Component 6: 0.000
Principal Component 7: 0.000
Principal Component 8: 0.000
Principal Component 9: 0.000
Principal Component 10: 0.000
Principal Component 11: 0.000
Principal Component 12: 0.000
Principal Component 13: 0.000
Principal Component 14: 0.000
Principal Component 15: 0.000
Principal Component 16: 0.000
Principal Component 17: 0.000</code></pre>
</div>
</div>
<p>Love PCA! Talk about it a bit here</p>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">10</span>))</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>sns.pairplot(data, diag_kind<span class="op">=</span><span class="st">'kde'</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Pairwise Scatter Plots'</span>)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>&lt;Figure size 864x720 with 0 Axes&gt;</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="analysis_files/figure-html/cell-10-output-2.png" class="img-fluid"></p>
</div>
</div>
<p>A gem of a chart. Unpack what’s going on here in detail, and give some examples (backed by science)</p>
<p>Now, I’ll go ahead and split the (training) data into training and testing sets, choosing an 80/20 split.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into features and target variable</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> data.drop([<span class="st">'DIC'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> data[<span class="st">'DIC'</span>]</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the data into training and testing sets</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(X, y, test_size<span class="op">=</span><span class="fl">0.20</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'X_train : </span><span class="sc">{</span>X_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'y_train : </span><span class="sc">{</span>y_train<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'X_test : </span><span class="sc">{</span>X_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'y_test : </span><span class="sc">{</span>y_test<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="model-selection-and-training" class="level2">
<h2 class="anchored" data-anchor-id="model-selection-and-training">Model Selection and Training</h2>
<p>I started by choosing Random Forest as my model of choice to predict DIC levels, but I found that XGBoost performs stronger on the training and testing data so I opted for that one instead.</p>
<p>I implemenet - Discuss your approach to model selection and hyperparameter tuning using techniques like RandomizedSearchCV and GridSearchCV - Share the results of your model training, including evaluation metrics like root mean squared error</p>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random Forest</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the hyperparameter grid</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>param_grid_rf <span class="op">=</span> {</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">500</span>],</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="va">None</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">20</span>],</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>],</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_features'</span>: [<span class="st">'auto'</span>, <span class="st">'sqrt'</span>, <span class="st">'log2'</span>]</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create and train the random forest model</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">1000</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X_train, y_train)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform RandomizedSearchCV</span></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>random_search <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>rf_model,</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>                                   param_distributions<span class="op">=</span>param_grid_rf,</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>                                   n_iter<span class="op">=</span><span class="dv">100</span>,</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>                                   cv<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>                                   scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>                                   random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>                                   n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>                                   verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit the RandomizedSearchCV on the training data</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>random_search.fit(X_train, y_train)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the best hyperparameters</span></span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Hyperparameters:"</span>, random_search.best_params_)</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the testing data</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> random_search.best_estimator_.predict(X_test)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, y_pred)</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y_test, y_pred)</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean Squared Error:"</span>, mse)</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean Absolute Error:"</span>, mae)</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"R-squared:"</span>, r2)</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform cross-validation on the training data</span></span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_val_score(random_search.best_estimator_, X_train, y_train, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>)</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>rmse_train <span class="op">=</span> <span class="op">-</span>np.mean(scores)</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training RMSE: </span><span class="sc">{</span>rmse_train<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions using the trained model</span></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">200</span>, </span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>                                 min_samples_split<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a>                                 min_samples_leaf<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>                                 max_features<span class="op">=</span><span class="st">'log2'</span>,</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>                                 max_depth<span class="op">=</span><span class="va">None</span>,</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a>                                 random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X, y)  <span class="co"># Assuming X_imputed and y are the imputed training data and target variable</span></span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> rf_model.predict(test_data)</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a submission DataFrame</span></span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>submission_df <span class="op">=</span> pd.DataFrame({<span class="st">'id'</span>: test_data[<span class="st">'id'</span>], <span class="st">'DIC'</span>: predictions})</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a><span class="co"># Save the submission DataFrame to a CSV file</span></span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a><span class="co"># submission_df.to_csv('submission.csv', index=False)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 100 candidates, totalling 500 fits
Best Hyperparameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}
Mean Squared Error: 30.34512666623212
Mean Absolute Error: 3.0584250779257967
R-squared: 0.9977299460851863
Training RMSE: 5.9632</code></pre>
</div>
</div>
<div class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor, AdaBoostRegressor</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameter grid for random forest</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>rf_param_grid <span class="op">=</span> {</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>],</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="va">None</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">4</span>]</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameter grid for AdaBoost</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>ada_param_grid <span class="op">=</span> {</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>],</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.1</span>, <span class="fl">1.0</span>]</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the base random forest model</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> RandomForestRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform grid search for random forest</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>rf_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>rf_model, param_grid<span class="op">=</span>rf_param_grid, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>rf_grid_search.fit(X_train, y_train)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best random forest model</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>best_rf_model <span class="op">=</span> rf_grid_search.best_estimator_</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the AdaBoost regressor with the best random forest as the base estimator</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>ada_model <span class="op">=</span> AdaBoostRegressor(base_estimator<span class="op">=</span>best_rf_model, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform grid search for AdaBoost</span></span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>ada_grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>ada_model, param_grid<span class="op">=</span>ada_param_grid, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>ada_grid_search.fit(X_train, y_train)</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best boosted random forest model</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>best_boosted_rf_model <span class="op">=</span> ada_grid_search.best_estimator_</span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set using the best boosted random forest model</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> best_boosted_rf_model.predict(X_test)</span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>mse <span class="op">=</span> mean_squared_error(y_test, predictions)</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Root Mean Squared Error:"</span>, np.sqrt(mse))</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the actual test data features</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>test_data_features <span class="op">=</span> test_data[X.columns]</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the actual test data using the best boosted random forest model</span></span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>predictions_actual_test_data <span class="op">=</span> best_boosted_rf_model.predict(test_data_features)</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>submission_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>    <span class="st">'id'</span>: test_data[<span class="st">'id'</span>],</span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>    <span class="st">'DIC'</span>: predictions_actual_test_data</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a>submission_csv_path <span class="op">=</span> <span class="st">'data/final_submission_boosted_rf_tuned.csv'</span></span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>submission_df.to_csv(submission_csv_path, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/maxwellpatterson/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.
  warnings.warn(</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Root Mean Squared Error: 5.4253004560182685</code></pre>
</div>
</div>
<div class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> RandomizedSearchCV</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>param_distributions <span class="op">=</span> {</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.01</span>, <span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>, <span class="fl">0.3</span>],</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">300</span>, <span class="dv">400</span>, <span class="dv">500</span>],</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>, <span class="dv">13</span>, <span class="dv">15</span>],</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: [<span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">1.0</span>],</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'colsample_bytree'</span>: [<span class="fl">0.3</span>, <span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.7</span>, <span class="fl">0.8</span>, <span class="fl">0.9</span>, <span class="fl">1.0</span>]              </span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the XGBoost model</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.XGBRegressor(random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform random search with cross-validation</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>random_search <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>xgb_model, </span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>                                   param_distributions<span class="op">=</span>param_distributions, </span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>                                   n_iter<span class="op">=</span><span class="dv">50</span>,  <span class="co"># Number of parameter settings to sample</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>                                   cv<span class="op">=</span><span class="dv">5</span>, </span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>                                   scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>,</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>                                   verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>                                   random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>random_search.fit(X_train, y_train)</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the best model and its parameters</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>best_model <span class="op">=</span> random_search.best_estimator_</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>best_params <span class="op">=</span> random_search.best_params_</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Best Parameters:"</span>, best_params)</span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions using the best model</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>y_pred <span class="op">=</span> best_model.predict(X_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Fitting 5 folds for each of 50 candidates, totalling 250 fits
Best Parameters: {'subsample': 0.6, 'n_estimators': 500, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 0.6}</code></pre>
</div>
</div>
<div class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the Mean Absolute Error (MAE)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>mae <span class="op">=</span> mean_absolute_error(y_test, y_pred)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the R-squared (R^2) score</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>r2 <span class="op">=</span> r2_score(y_test, y_pred)</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the MAE and R^2 scores</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Mean Absolute Error (MAE):"</span>, mae)</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"R-squared (R^2) Score:"</span>, r2)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mean Absolute Error (MAE): 3.134408275853739
R-squared (R^2) Score: 0.9978656383611391</code></pre>
</div>
</div>
<div class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the dataset into a data structure that XGBoost supports</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(X_train, label<span class="op">=</span>y_train)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(X_test, label<span class="op">=</span>y_test)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameters for the XGBoost model</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>params <span class="op">=</span> {</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: <span class="fl">0.05</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: <span class="dv">500</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: <span class="dv">3</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: <span class="fl">0.6</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'colsample_bytree'</span>: <span class="fl">0.6</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'objective'</span>: <span class="st">'reg:squarederror'</span>,  </span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="st">'random_state'</span>: <span class="dv">42</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the number of cross-validation folds and the metrics for evaluation</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>cv_results <span class="op">=</span> xgb.cv(</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>    dtrain<span class="op">=</span>dtrain,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>params,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    nfold<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    num_boost_round<span class="op">=</span><span class="dv">500</span>,  <span class="co"># The number of boosting rounds or trees to build</span></span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>    early_stopping_rounds<span class="op">=</span><span class="dv">50</span>,  <span class="co"># Stop if the metric does not improve in these many rounds</span></span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span><span class="st">"rmse"</span>,  </span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>    as_pandas<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb24-25"><a href="#cb24-25" aria-hidden="true" tabindex="-1"></a>    seed<span class="op">=</span><span class="dv">13</span></span>
<span id="cb24-26"><a href="#cb24-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-27"><a href="#cb24-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-28"><a href="#cb24-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Display the CV results</span></span>
<span id="cb24-29"><a href="#cb24-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(cv_results)</span>
<span id="cb24-30"><a href="#cb24-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-31"><a href="#cb24-31" aria-hidden="true" tabindex="-1"></a>best_num_boost_round <span class="op">=</span> <span class="bu">len</span>(cv_results)</span>
<span id="cb24-32"><a href="#cb24-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-33"><a href="#cb24-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Train the model with the best number of boosting rounds</span></span>
<span id="cb24-34"><a href="#cb24-34" aria-hidden="true" tabindex="-1"></a>final_model <span class="op">=</span> xgb.train(</span>
<span id="cb24-35"><a href="#cb24-35" aria-hidden="true" tabindex="-1"></a>    params<span class="op">=</span>params,</span>
<span id="cb24-36"><a href="#cb24-36" aria-hidden="true" tabindex="-1"></a>    dtrain<span class="op">=</span>dtrain,</span>
<span id="cb24-37"><a href="#cb24-37" aria-hidden="true" tabindex="-1"></a>    num_boost_round<span class="op">=</span>best_num_boost_round</span>
<span id="cb24-38"><a href="#cb24-38" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-39"><a href="#cb24-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-40"><a href="#cb24-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set</span></span>
<span id="cb24-41"><a href="#cb24-41" aria-hidden="true" tabindex="-1"></a>predictions <span class="op">=</span> final_model.predict(dtest)</span>
<span id="cb24-42"><a href="#cb24-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-43"><a href="#cb24-43" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the final model (you can use any evaluation metric that suits your problem)</span></span>
<span id="cb24-44"><a href="#cb24-44" aria-hidden="true" tabindex="-1"></a>final_mse_cv <span class="op">=</span> cv_results[<span class="st">'test-rmse-mean'</span>].iloc[<span class="op">-</span><span class="dv">1</span>] <span class="co"># Last row's RMSE squared to get MSE</span></span>
<span id="cb24-45"><a href="#cb24-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Root Mean Squared Error:"</span>, final_mse_cv)</span>
<span id="cb24-46"><a href="#cb24-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-47"><a href="#cb24-47" aria-hidden="true" tabindex="-1"></a><span class="co"># Ensure test_data_features is prepared with the same features as those used during the model training</span></span>
<span id="cb24-48"><a href="#cb24-48" aria-hidden="true" tabindex="-1"></a>test_data_features <span class="op">=</span> test_data[X.columns]  <span class="co"># Assuming 'X.columns' contains the correct features</span></span>
<span id="cb24-49"><a href="#cb24-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-50"><a href="#cb24-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a DMatrix for the actual test data (test_data_features)</span></span>
<span id="cb24-51"><a href="#cb24-51" aria-hidden="true" tabindex="-1"></a>dtest_actual <span class="op">=</span> xgb.DMatrix(test_data_features)</span>
<span id="cb24-52"><a href="#cb24-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-53"><a href="#cb24-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the trained model to make predictions on the actual test dataset</span></span>
<span id="cb24-54"><a href="#cb24-54" aria-hidden="true" tabindex="-1"></a>predictions_actual_test_data <span class="op">=</span> final_model.predict(dtest_actual)</span>
<span id="cb24-55"><a href="#cb24-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-56"><a href="#cb24-56" aria-hidden="true" tabindex="-1"></a>submission_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb24-57"><a href="#cb24-57" aria-hidden="true" tabindex="-1"></a>    <span class="st">'id'</span>: test_data[<span class="st">'id'</span>],  </span>
<span id="cb24-58"><a href="#cb24-58" aria-hidden="true" tabindex="-1"></a>    <span class="st">'DIC'</span>: predictions_actual_test_data</span>
<span id="cb24-59"><a href="#cb24-59" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb24-60"><a href="#cb24-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-61"><a href="#cb24-61" aria-hidden="true" tabindex="-1"></a>submission_csv_path <span class="op">=</span> <span class="st">'data/final_submission_rs.csv'</span> </span>
<span id="cb24-62"><a href="#cb24-62" aria-hidden="true" tabindex="-1"></a>submission_df.to_csv(submission_csv_path, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/maxwellpatterson/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [22:22:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: 
Parameters: { "n_estimators" } are not used.

  warnings.warn(smsg, UserWarning)
/Users/maxwellpatterson/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [22:22:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: 
Parameters: { "n_estimators" } are not used.

  warnings.warn(smsg, UserWarning)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>     train-rmse-mean  train-rmse-std  test-rmse-mean  test-rmse-std
0         107.004785        0.792631      107.085641       3.286523
1         101.791400        0.771185      101.870388       3.162677
2          96.834267        0.729556       96.919886       3.048361
3          92.131780        0.687460       92.245071       2.934377
4          87.665866        0.648326       87.767277       2.834403
..               ...             ...             ...            ...
495         2.481191        0.057729        6.203033       0.560730
496         2.476859        0.055060        6.202946       0.560677
497         2.473785        0.054023        6.201595       0.560396
498         2.470109        0.051466        6.202116       0.560695
499         2.465697        0.052848        6.202022       0.560889

[500 rows x 4 columns]
Root Mean Squared Error: 6.202021641713651</code></pre>
</div>
</div>
<div class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert the dataset into a data structure that XGBoost supports</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>dtrain <span class="op">=</span> xgb.DMatrix(X_train, label<span class="op">=</span>y_train)</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>dtest <span class="op">=</span> xgb.DMatrix(X_test, label<span class="op">=</span>y_test)</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the parameter sets for different XGBoost models</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>params_list <span class="op">=</span> [</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'learning_rate'</span>: <span class="fl">0.05</span>, <span class="st">'n_estimators'</span>: <span class="dv">500</span>, <span class="st">'max_depth'</span>: <span class="dv">3</span>, <span class="st">'subsample'</span>: <span class="fl">0.6</span>, <span class="st">'colsample_bytree'</span>: <span class="fl">0.6</span>},</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'learning_rate'</span>: <span class="fl">0.1</span>, <span class="st">'n_estimators'</span>: <span class="dv">300</span>, <span class="st">'max_depth'</span>: <span class="dv">5</span>, <span class="st">'subsample'</span>: <span class="fl">0.8</span>, <span class="st">'colsample_bytree'</span>: <span class="fl">0.8</span>},</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    {<span class="st">'learning_rate'</span>: <span class="fl">0.02</span>, <span class="st">'n_estimators'</span>: <span class="dv">1000</span>, <span class="st">'max_depth'</span>: <span class="dv">4</span>, <span class="st">'subsample'</span>: <span class="fl">0.7</span>, <span class="st">'colsample_bytree'</span>: <span class="fl">0.7</span>}</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty list to store the trained models</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> []</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Train multiple XGBoost models with different parameter settings</span></span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> params <span class="kw">in</span> params_list:</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    params[<span class="st">'objective'</span>] <span class="op">=</span> <span class="st">'reg:squarederror'</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    params[<span class="st">'random_state'</span>] <span class="op">=</span> <span class="dv">42</span></span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>    cv_results <span class="op">=</span> xgb.cv(</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>        dtrain<span class="op">=</span>dtrain,</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>        params<span class="op">=</span>params,</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>        nfold<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>        num_boost_round<span class="op">=</span><span class="dv">500</span>,</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>        early_stopping_rounds<span class="op">=</span><span class="dv">50</span>,</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        metrics<span class="op">=</span><span class="st">"rmse"</span>,</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>        as_pandas<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a>        seed<span class="op">=</span><span class="dv">13</span></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-30"><a href="#cb27-30" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a>    best_num_boost_round <span class="op">=</span> <span class="bu">len</span>(cv_results)</span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> xgb.train(</span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a>        params<span class="op">=</span>params,</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a>        dtrain<span class="op">=</span>dtrain,</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a>        num_boost_round<span class="op">=</span>best_num_boost_round</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>    models.append(model)</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Predict on the test set using each model and compute the average predictions</span></span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>ensemble_predictions <span class="op">=</span> np.zeros(dtest.num_row())</span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model <span class="kw">in</span> models:</span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a>    predictions <span class="op">=</span> model.predict(dtest)</span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a>    ensemble_predictions <span class="op">+=</span> predictions</span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>ensemble_predictions <span class="op">/=</span> <span class="bu">len</span>(models)</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the ensemble model</span></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>final_mse_cv <span class="op">=</span> mean_squared_error(y_test, ensemble_predictions)</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Root Mean Squared Error:"</span>, np.sqrt(final_mse_cv))</span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the actual test data features</span></span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a>test_data_features <span class="op">=</span> test_data[X.columns]</span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a>dtest_actual <span class="op">=</span> xgb.DMatrix(test_data_features)</span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a><span class="co"># Make predictions on the actual test data using the ensemble model</span></span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a>ensemble_predictions_actual_test_data <span class="op">=</span> np.zeros(dtest_actual.num_row())</span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> model <span class="kw">in</span> models:</span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a>    predictions_actual_test_data <span class="op">=</span> model.predict(dtest_actual)</span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>    ensemble_predictions_actual_test_data <span class="op">+=</span> predictions_actual_test_data</span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a>ensemble_predictions_actual_test_data <span class="op">/=</span> <span class="bu">len</span>(models)</span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>submission_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>    <span class="st">'id'</span>: test_data[<span class="st">'id'</span>],</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a>    <span class="st">'DIC'</span>: ensemble_predictions_actual_test_data</span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-68"><a href="#cb27-68" aria-hidden="true" tabindex="-1"></a>submission_csv_path <span class="op">=</span> <span class="st">'data/final_submission_ensemble.csv'</span></span>
<span id="cb27-69"><a href="#cb27-69" aria-hidden="true" tabindex="-1"></a>submission_df.to_csv(submission_csv_path, index<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/Users/maxwellpatterson/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [22:27:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: 
Parameters: { "n_estimators" } are not used.

  warnings.warn(smsg, UserWarning)
/Users/maxwellpatterson/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [22:27:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: 
Parameters: { "n_estimators" } are not used.

  warnings.warn(smsg, UserWarning)
/Users/maxwellpatterson/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [22:27:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: 
Parameters: { "n_estimators" } are not used.

  warnings.warn(smsg, UserWarning)
/Users/maxwellpatterson/opt/anaconda3/lib/python3.8/site-packages/xgboost/core.py:160: UserWarning: [22:27:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:742: 
Parameters: { "n_estimators" } are not used.

  warnings.warn(smsg, UserWarning)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Root Mean Squared Error: 5.436212225017084</code></pre>
</div>
</div>
</section>
<section id="model-evaluation-and-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="model-evaluation-and-interpretation">Model Evaluation and Interpretation</h2>
<ul>
<li>Interpret the model results, including analyzing feature importances to understand which variables are most predictive of DIC levels</li>
<li>Discuss any limitations or caveats to your modeling approach</li>
</ul>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Learning Curve</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> learning_curve</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>train_sizes, train_scores, test_scores <span class="op">=</span> learning_curve(</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    estimator<span class="op">=</span>xgb.XGBRegressor(objective<span class="op">=</span><span class="st">'reg:squarederror'</span>, <span class="op">**</span>best_params),</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    X<span class="op">=</span>X, y<span class="op">=</span>y,</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    train_sizes<span class="op">=</span>np.linspace(<span class="fl">0.1</span>, <span class="fl">1.0</span>, <span class="dv">10</span>),</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'neg_mean_squared_error'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the learning curve</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Learning Curve"</span>)</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Training Set Size"</span>)</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Negative Mean Squared Error"</span>)</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>plt.plot(train_sizes, <span class="op">-</span>train_scores.mean(axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span><span class="st">"Training score"</span>)</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>plt.plot(train_sizes, <span class="op">-</span>test_scores.mean(axis<span class="op">=</span><span class="dv">1</span>), label<span class="op">=</span><span class="st">"Cross-validation score"</span>)</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a>plt.legend(loc<span class="op">=</span><span class="st">"best"</span>)</span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="analysis_files/figure-html/cell-18-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Feature Importance</span></span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>xgb_model <span class="op">=</span> xgb.XGBRegressor(objective<span class="op">=</span><span class="st">'reg:squarederror'</span>, <span class="op">**</span>best_params)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>xgb_model.fit(X_train, y_train)</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>feature_importances <span class="op">=</span> xgb_model.feature_importances_</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>indices <span class="op">=</span> np.argsort(feature_importances)[::<span class="op">-</span><span class="dv">1</span>]</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>plt.figure()</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Feature Importances"</span>)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>plt.bar(<span class="bu">range</span>(X_train.shape[<span class="dv">1</span>]), feature_importances[indices],</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>        color<span class="op">=</span><span class="st">"r"</span>, align<span class="op">=</span><span class="st">"center"</span>)</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>plt.xticks(<span class="bu">range</span>(X_train.shape[<span class="dv">1</span>]), X_train.columns[indices], rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>plt.xlim([<span class="op">-</span><span class="dv">1</span>, X_train.shape[<span class="dv">1</span>]])</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="analysis_files/figure-html/cell-19-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training set sizes:"</span>, train_sizes)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Training scores (Negative MSE):</span><span class="ch">\n</span><span class="st">"</span>, train_scores)</span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Validation scores (Negative MSE):</span><span class="ch">\n</span><span class="st">"</span>, test_scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training set sizes: [ 116  232  348  465  581  697  814  930 1046 1163]
Training scores (Negative MSE):
 [[-9.99956912e-05 -4.48875931e-05 -4.48875931e-05 -4.48875931e-05
  -4.48875931e-05]
 [-4.85965430e-03 -3.58756928e-03 -3.58756928e-03 -3.58756928e-03
  -3.58756928e-03]
 [-3.33106308e-02 -1.89585256e-02 -2.17123444e-02 -2.17123444e-02
  -2.17123444e-02]
 [-9.33256137e-02 -7.01989493e-02 -7.85154216e-02 -7.85154216e-02
  -7.85154216e-02]
 [-1.72739081e-01 -1.44003641e-01 -1.30381761e-01 -1.30381761e-01
  -1.30381761e-01]
 [-2.39533868e-01 -2.50730626e-01 -2.47338423e-01 -2.37732325e-01
  -2.37732325e-01]
 [-3.57112494e-01 -3.55847598e-01 -4.22327769e-01 -3.91398858e-01
  -3.91398858e-01]
 [-4.74316204e-01 -4.70541422e-01 -5.23268350e-01 -4.72926254e-01
  -5.08711505e-01]
 [-6.05465066e-01 -6.20304339e-01 -7.32547199e-01 -6.19882345e-01
  -5.86780844e-01]
 [-8.57564023e-01 -8.76077021e-01 -8.59182856e-01 -7.92936413e-01
  -7.84635593e-01]]
Validation scores (Negative MSE):
 [[ -88.89479412 -158.46259056 -271.48825789 -110.64162757 -216.62701914]
 [ -55.14024621  -76.68824704 -179.0780735   -76.20979962 -162.88731402]
 [ -55.40054979  -79.14679055 -127.59255391  -60.64779931 -125.58908661]
 [ -53.24218439  -35.07228322  -85.82395188 -101.90416245  -90.12854895]
 [ -51.65801281  -37.81445262  -41.40162724  -51.56235276  -40.24510824]
 [ -50.53647034  -36.92644596  -32.90932525  -45.27700885  -37.66795763]
 [ -50.13721302  -36.24273256  -29.95333699  -33.45592183  -31.57463821]
 [ -48.17150708  -30.14362447  -26.10883187  -32.37393992  -33.36267632]
 [ -45.73562739  -29.60455241  -27.58651309  -34.08429642  -33.62065259]
 [ -46.78893235  -25.05317752  -26.90810602  -32.3449201   -30.56800386]]</code></pre>
</div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>learning_curve_data <span class="op">=</span> pd.DataFrame({</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Training Set Size'</span>: train_sizes,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Training Score (Negative MSE)'</span>: train_scores.mean(axis<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'Validation Score (Negative MSE)'</span>: test_scores.mean(axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(learning_curve_data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   Training Set Size  Training Score (Negative MSE)  \
0                116                      -0.000056   
1                232                      -0.003842   
2                348                      -0.023481   
3                465                      -0.079814   
4                581                      -0.141578   
5                697                      -0.242614   
6                814                      -0.383617   
7                930                      -0.489953   
8               1046                      -0.632996   
9               1163                      -0.834079   

   Validation Score (Negative MSE)  
0                      -169.222858  
1                      -110.000736  
2                       -89.675356  
3                       -73.234226  
4                       -44.536311  
5                       -40.663442  
6                       -36.272769  
7                       -34.032116  
8                       -34.126328  
9                       -32.332628  </code></pre>
</div>
</div>
</section>
<section id="implications-and-future-work" class="level2">
<h2 class="anchored" data-anchor-id="implications-and-future-work">Implications and Future Work</h2>
<ul>
<li>Explain how predictive model could be useful for oceanographic research and understanding the carbon cycle</li>
<li>Discuss potential applications of model, such as identifying areas of high or low DIC, or predicting future changes in ocean chemistry</li>
<li>Suggest future work or improvements to analysis, such as incorporating additional data sources or trying more advanced modeling techniques</li>
</ul>
</section>
<section id="conclusion" class="level2">
<h2 class="anchored" data-anchor-id="conclusion">Conclusion</h2>
<ul>
<li>Summarize the key findings of analysis and the performance of machine learning model</li>
<li>Reiterate the importance of understanding and predicting DIC levels in the ocean</li>
<li>Encourage readers to explore the code and data further and contribute to oceanographic research</li>
</ul>
</section>
<section id="acknowledgments" class="level2">
<h2 class="anchored" data-anchor-id="acknowledgments">Acknowledgments</h2>
<ul>
<li>Acknowledge the CalCOFI program and any other sources of data or inspiration for your project</li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>